# ğŸ§  DevHelper AI

**Chat with your codebase using LLMs!**  
Analyze local projects, GitHub repos, or entire websites with **OpenAI** (online/cloud) or **Ollama** (local/dev, optional).

ğŸŒ **Live Demo:** [https://devhelper-ai.onrender.com](https://devhelper-ai.onrender.com)

---

## ğŸš€ Features

- ğŸ” **RAG** (Retrieval-Augmented Generation) + Chunking + Vector Search
- ğŸ“‚ Local folders or Docker-mounted volumes
- ğŸŒ GitHub repo & Website content support
- ğŸ§  Supports **OpenAI** (cloud, always) and **Ollama** (local, optional)
- ğŸ§± ChromaDB persistence (vector store)
- ğŸ’¬ Streamlit-based chat UI
- ğŸ“¥ Export chat history (JSON)

---

## âš™ï¸ Quick Start

### ğŸ—ï¸ **Local/Dev Mode** (OpenAI or Ollama)

```bash
git clone https://github.com/XessX/devhelper-ai
cd devhelper-ai
cp .env.example .env
# Add your OpenAI API key to .env
pip install -r requirements.txt
streamlit run app.py
Optionally, for Docker/Ollama (local RAG):

# PowerShell
.\run-devhelper.ps1

# OR, if on bash:
docker build -t devhelper-ai .
docker run -it -p 8501:8501 -v "$(pwd):/mounted" --env-file .env devhelper-ai
â˜ï¸ Cloud/Render Deployment (OpenAI-only)
Push to GitHub:
https://github.com/XessX/devhelper-ai

One-click deploy using render.yaml

Set your Render environment variable:

OPENAI_API_KEY=your-openai-key
âš ï¸ Note
On Render (and any online cloud host), only OpenAI is supported.

Ollama is only available for local Docker/dev use.

The app will auto-select OpenAI on Render/cloud; no user/accidental Ollama usage.

ğŸ’¡ Use Cases
Chat with unfamiliar codebases

Understand legacy repositories

Explore or debug GitHub projects interactively

Extract architecture or README details

Scrape & summarize documentation sites

ğŸ“ Project Structure

devhelper-ai/
â”œâ”€â”€ app.py                  # Streamlit frontend
â”œâ”€â”€ rag_engine/             # Code loaders, chunkers, RAG logic
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ loader.py
â”‚   â”œâ”€â”€ query_engine.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ vector_store.py
â”œâ”€â”€ Dockerfile              # Docker container (local, dev)
â”œâ”€â”€ run-devhelper.ps1       # PowerShell launcher for Docker
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example            # Env variable template
â”œâ”€â”€ render.yaml             # Render deploy spec
â””â”€â”€ README.md               # Youâ€™re reading it!
ğŸ‘¨â€ğŸ’» Author
DevHelper AI by Al Jubair Hossain

GitHub: @XessX

LinkedIn: al-jubair-hossain

ğŸ™Œ Acknowledgments
LangChain

Ollama

ChromaDB

Streamlit

ğŸ›¡ï¸ LLM Engine Policy
OpenAI: Always available, required for online/cloud (Render, etc.)

Ollama: Only available in local Docker/dev environments.

On Render/cloud, Ollama is disabled & cannot be selected.

The app will auto-select OpenAI on Render; no user/accidental Ollama usage.

ğŸ“¥ Export/Import
Download chat logs as .json for research or reuse.

Enjoy your AI-powered codebase assistant!